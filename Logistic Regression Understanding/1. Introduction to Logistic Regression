This is the Notes and Code for the Logistic Regression.

Here, we have just learned about the Logistic Regression and Cost function:

  Logistic regression is made up of Simple Regression and Sigmoid function that is the
  main reason we called this as Logistic Regression.

L2 Regularisation is used to reduce the Overfitting.

We are learning something in the Logistic Regression.


Checking the Accuracy of the Model.

DATASET : Imbalanced DATASET.

in case of imbalanced DATASET we have to use different technique thatis precision.

TP/TP+FP

Out of actual values how many are correctly predicted.

We are considering the Recall, 


Confusion Matriz makesometime the blunder.
-- 





Just revise and review the concep of Decision tree: From here decision tree has been started vy savita.

just chekcing the ginny impurity and Entropy for the ID3

We have problem statement of the picture we have to decide the actual one.

Decide the famaily winter image.

We are deciding the more real feature iamge.

-- we are getting the information. More and More 


-- over the more decision we are getting the actual information.


Will update the written things on the OneNote.

Understaning of the Data Science is Pending. Will resume Sooner.





